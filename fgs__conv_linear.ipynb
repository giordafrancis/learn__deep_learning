{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fa938f-2366-4422-9113-35d491e0d083",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Why is a convolution layer on a 1x1 input is identical to a linear layer.\n",
    "\n",
    "code example an explanation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af843a97-16c8-4672-80d1-23839c02511f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3367]],\n",
       "\n",
       "         [[0.1288]],\n",
       "\n",
       "         [[0.2345]]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a 1x1 input (batch_size=1, channels=3, height=1, width=1)\n",
    "input_tensor = torch.randn(1, 3, 1, 1) \n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93659ed0-cbc1-4715-994e-10fc24fdf52f",
   "metadata": {},
   "source": [
    "## Convolution Layer\n",
    "Now, let's create a 1x1 convolution layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3109cea4-be9c-411b-bd33-9c5b3eb3f78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution output shape: torch.Size([1, 2, 1, 1])\n",
      "Convolution output: tensor([[[[0.5129]],\n",
      "\n",
      "         [[0.0281]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create a 1x1 convolution layer (in_channels=3, out_channels=2)\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=1)\n",
    "\n",
    "# Apply the convolution\n",
    "conv_output = conv_layer(input_tensor)\n",
    "\n",
    "print(\"Convolution output shape:\", conv_output.shape)\n",
    "print(\"Convolution output:\", conv_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39cb54d-e9d9-4ae3-918a-4a2ceb5a5d14",
   "metadata": {},
   "source": [
    "## Linear Layer\n",
    "Next, we'll create an equivalent linear layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b26fa77-258b-45ad-bb0d-6f06ce966237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2320788c-32cb-4ab8-b082-06dcea7a7cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear output shape: torch.Size([1, 2])\n",
      "Linear output: tensor([[0.5129, 0.0281]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create an equivalent linear layer\n",
    "linear_layer = nn.Linear(in_features=3, out_features=2)\n",
    "\n",
    "# Ensure the linear layer has the same weights and bias as the conv layer\n",
    "# note this is the kernel o\n",
    "with torch.no_grad():\n",
    "    linear_layer.weight.copy_(conv_layer.weight.view(2, 3))\n",
    "    linear_layer.bias.copy_(conv_layer.bias)\n",
    "\n",
    "# Reshape the input tensor for the linear layer\n",
    "linear_input = input_tensor.view(1, 3)\n",
    "\n",
    "# Apply the linear transformation\n",
    "linear_output = linear_layer(linear_input)\n",
    "\n",
    "print(\"Linear output shape:\", linear_output.shape)\n",
    "print(\"Linear output:\", linear_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019408a7-4e36-47bf-8ea9-c3984647554b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5129, 0.0281]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_input @ linear_layer.weight.T + linear_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f62bd7-75d1-4972-8e58-0257b98e599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the outputs equal? True\n"
     ]
    }
   ],
   "source": [
    "# Compare the outputs\n",
    "print(\"Are the outputs equal?\", torch.allclose(conv_output.squeeze(), linear_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b841c3-b8b4-4b59-8aa6-11f893322542",
   "metadata": {},
   "source": [
    "This code demonstrates that:\n",
    "\n",
    "- The 1x1 convolution operates on a 4D tensor (batch, channels, height, width), while the linear layer operates on a 2D tensor (batch, features).\n",
    "- When we reshape the input and use the same weights and biases, the outputs are identical.\n",
    "- The only difference is in the shape of the output: the convolution preserves the 4D structure, while the linear layer produces a 2D output.\n",
    "\n",
    "This equivalence is why 1x1 convolutions are often used in neural network architectures for dimensionality reduction or feature mixing across channels, effectively acting as learned linear transformations applied to each spatial location independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f04c3880-b823-4c63-89d2-56aa7d014429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Create input: shape (batch_size, channels, height, width)\n",
    "#    For 1x1 convolution, height and width are 1\n",
    "input_data = np.random.rand(1, 3, 1, 1)\n",
    "\n",
    "# 2. Create weights: shape (output_channels, input_channels, kernel_height, kernel_width)\n",
    "#    For 1x1 convolution, kernel_height and kernel_width are 1\n",
    "weights = np.random.rand(2, 3, 1, 1)\n",
    "\n",
    "# 3. Create bias: shape (output_channels,)\n",
    "bias = np.random.rand(2)\n",
    "\n",
    "# 4. Perform 1x1 convolution\n",
    "def conv_1x1(input_data, weights, bias):\n",
    "    # Reshape input: (1, 3, 1, 1) -> (3,)\n",
    "    input_flat = input_data.reshape(-1)\n",
    "    \n",
    "    # Reshape weights: (2, 3, 1, 1) -> (2, 3)\n",
    "    weights_flat = weights.reshape(weights.shape[0], -1)\n",
    "    \n",
    "    # Perform dot product\n",
    "    output = np.dot(weights_flat, input_flat) + bias\n",
    "    \n",
    "    # Reshape output to (1, 2, 1, 1)\n",
    "    return output.reshape(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d7b108-ec4a-4c10-907f-e69e29e439d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37454012, 0.95071431, 0.73199394])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed8d7d20-7e4b-4f40-ba80-38db0b7862b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manual calculation output:\n",
      " [[[[1.19481039]]\n",
      "\n",
      "  [[1.30583774]]]]\n",
      "Are they equal? True\n"
     ]
    }
   ],
   "source": [
    "# 5. Compute the output\n",
    "output = conv_1x1(input_data, weights, bias)\n",
    "\n",
    "# print(\"Input shape:\", input_data.shape)\n",
    "# print(\"Input data:\\n\", input_data)\n",
    "# print(\"\\nWeights shape:\", weights.shape)\n",
    "# print(\"Weights:\\n\", weights)\n",
    "# print(\"\\nBias:\", bias)\n",
    "# print(\"\\nOutput shape:\", output.shape)\n",
    "# print(\"Output:\\n\", output)\n",
    "\n",
    "# 6. Verify with manual calculation\n",
    "manual_output = np.zeros((1, 2, 1, 1))\n",
    "for i in range(2):  # For each output channel\n",
    "    manual_output[0, i, 0, 0] = np.sum(input_data[0, :, 0, 0] * weights[i, :, 0, 0]) + bias[i]\n",
    "\n",
    "print(\"\\nManual calculation output:\\n\", manual_output)\n",
    "print(\"Are they equal?\", np.allclose(output, manual_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2035089-0847-4583-999c-0af3bb953c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.19481039]],\n",
       "\n",
       "        [[1.30583774]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae521f8c-53e6-4529-92be-349f33acf502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37454012, 0.95071431, 0.73199394])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786d7be4-7767-4914-b48d-5748ee14ddc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 1, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb40456-1514-4665-83cf-580e8ba4e6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of conv_layer.weight: torch.Size([2, 3, 3, 3])\n",
      "\n",
      "Kernels (weights) of the convolutional layer:\n",
      "Kernel for output channel 0:\n",
      "tensor([[[ 0.1471,  0.1597, -0.0451],\n",
      "         [ 0.1768, -0.0422,  0.0388],\n",
      "         [-0.0937,  0.1130,  0.1697]],\n",
      "\n",
      "        [[-0.1412,  0.1673,  0.0360],\n",
      "         [ 0.1422,  0.0261,  0.0928],\n",
      "         [-0.0272,  0.1484,  0.0284]],\n",
      "\n",
      "        [[-0.0898,  0.0491, -0.0887],\n",
      "         [-0.0226, -0.0782,  0.1277],\n",
      "         [-0.1519, -0.0887, -0.0543]]], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Kernel for output channel 1:\n",
      "tensor([[[-0.1157,  0.0182, -0.1901],\n",
      "         [ 0.1738, -0.1635,  0.1486],\n",
      "         [ 0.0320, -0.0625,  0.1189]],\n",
      "\n",
      "        [[ 0.0300,  0.1555,  0.0210],\n",
      "         [-0.0607,  0.0517, -0.0522],\n",
      "         [ 0.0810,  0.1718,  0.1112]],\n",
      "\n",
      "        [[-0.0841,  0.1111,  0.0344],\n",
      "         [ 0.0977, -0.1173, -0.1905],\n",
      "         [-0.0744, -0.1476,  0.1579]]], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Are kernels the same as weights? True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a convolutional layer\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, padding=1)\n",
    "\n",
    "# Print the shape of the weights\n",
    "print(\"Shape of conv_layer.weight:\", conv_layer.weight.shape)\n",
    "\n",
    "# Access the kernels/weights\n",
    "kernels = conv_layer.weight\n",
    "\n",
    "print(\"\\nKernels (weights) of the convolutional layer:\")\n",
    "for i, kernel in enumerate(kernels):\n",
    "    print(f\"Kernel for output channel {i}:\")\n",
    "    print(kernel)\n",
    "    print()\n",
    "\n",
    "# Demonstrate that kernels are indeed the weights\n",
    "print(\"Are kernels the same as weights?\", torch.equal(kernels, conv_layer.weight))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbf1504-b27b-4ac9-8ee4-d33f6fa5112b",
   "metadata": {},
   "source": [
    "## What are Pointwise (1x1) convolutional layers?\n",
    "\n",
    "Pointwise convolutions, also known as 1x1 convolutions, are a special type of convolutional layer that operates on each pixel independently across all channels. They are widely used in deep learning architectures for various purposes, including dimensionality reduction, feature combination, and computational efficiency. Let's explore pointwise convolutions and their applications using PyTorch examples.\n",
    "\n",
    "### Pointwise Convolutions Explained\n",
    "\n",
    "A pointwise convolution uses a 1x1 kernel that iterates through every single point in the input tensor. It effectively performs a linear combination of the input channels at each spatial location, allowing for cross-channel information mixing without affecting the spatial dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0faa804c-3f79-429c-a966-06fa823c1cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 64, 32, 32])\n",
      "Output shape: torch.Size([1, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Input tensor: (batch_size, in_channels, height, width)\n",
    "input_tensor = torch.randn(1, 64, 32, 32)\n",
    "\n",
    "# Pointwise convolution layer\n",
    "pointwise_conv = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1)\n",
    "\n",
    "# Apply pointwise convolution\n",
    "output = pointwise_conv(input_tensor)\n",
    "\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567bbcf6-d5d1-4dd1-a8f1-7467d233d381",
   "metadata": {},
   "source": [
    "In this example, we create a pointwise convolution layer that transforms a tensor with 64 input channels into 128 output channels, maintaining the spatial dimensions (32x32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9ac0a-7745-4f71-9aeb-369fc48ccb72",
   "metadata": {},
   "source": [
    "### Applications of Pointwise Convolutions\n",
    "Pointwise convolutions are used in various ways by practitioners in deep learning:\n",
    "\n",
    "    1. Dimensionality Reduction\n",
    "\n",
    "Pointwise convolutions can efficiently reduce the number of channels in a feature map, decreasing computational complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b993586-7037-4907-835f-28bad8f9ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced features shape: torch.Size([1, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "dim_reduction = nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1)\n",
    "reduced_features = dim_reduction(torch.randn(1, 256, 32, 32))\n",
    "print(f\"Reduced features shape: {reduced_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b909e561-d8e8-43f3-9fc6-24b9e7608dbd",
   "metadata": {},
   "source": [
    "2. Network-in-Network Architecture\n",
    "\n",
    "Pointwise convolutions are key components in Network-in-Network architectures, adding non-linearity between layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bd6daa2-b112-4391-8de9-e4a2397cbff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIN output shape: torch.Size([1, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class NetworkInNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.pointwise1 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.pointwise2 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.pointwise1(x))\n",
    "        x = torch.relu(self.pointwise2(x))\n",
    "        return x\n",
    "\n",
    "nin_model = NetworkInNetwork()\n",
    "output = nin_model(torch.randn(1, 3, 32, 32))\n",
    "print(f\"NIN output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9111c-f049-4728-b6ca-48e8f426076c",
   "metadata": {},
   "source": [
    "Pointwise convolutions are versatile and computationally efficient, making them a popular choice in modern deep learning architectures. They allow for flexible channel manipulation without affecting spatial dimensions, enabling the creation of more compact and efficient models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
